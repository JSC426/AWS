{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUCKET:  text-encoder-227921966468\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "#bucket = sess.default_bucket()\n",
    "\n",
    "\n",
    "def create_bucket(bucket_name, region=None):\n",
    "    \"\"\"Create an S3 bucket in a specified region\n",
    "\n",
    "    If a region is not specified, the bucket is created in the S3 default\n",
    "    region (us-east-1).\n",
    "\n",
    "    :param bucket_name: Bucket to create\n",
    "    :param region: String region to create bucket in, e.g., 'us-west-2'\n",
    "    :return: True if bucket created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bucket\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3_client = boto3.client('s3', region_name=region)\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ENDPOINT_NAME = \"text-encoder\"\n",
    "WORKFLOW_DATE_TIME = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "BUCKET = \"{}-{}\".format(ENDPOINT_NAME, account)\n",
    "\n",
    "create_bucket(bucket_name=BUCKET, region=None)\n",
    "\n",
    "\n",
    "print(\"BUCKET: \", BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Entry-Point Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_encoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile text_encoder.py\n",
    "import tarfile\n",
    "import boto3\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from sagemaker_containers.beta.framework import worker, encoders\n",
    "#from six import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "def pip_upgrade(package):\n",
    "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package])\n",
    "\n",
    "def pip_install(package):\n",
    "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
    "\n",
    "print('********** Pip Install TF-Hub **********')\n",
    "pip_upgrade('setuptools')\n",
    "pip_install('tensorflow>=1.7')\n",
    "pip_install('tensorflow_hub')\n",
    "pip_install('sentencepiece')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import sentencepiece as spm\n",
    "\n",
    "import glob\n",
    "import hashlib\n",
    "print('********** Copying BERT-Lite **********')\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-lite/2\"\n",
    "os.environ['TFHUB_CACHE_DIR'] = \"/opt/ml/bert_lite_module_cache\"\n",
    "\n",
    "# Reduce logging output.\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "def process_to_IDs_in_sparse_format(sp, sentences):\n",
    "    \"\"\"An utility method that processes sentences with the\n",
    "       sentence piece processor 'sp' and returns the results in \n",
    "       tf.SparseTensor-similar format: (values, indices, dense_shape)\n",
    "    \"\"\"\n",
    "    ids = [sp.EncodeAsIds(x) for x in sentences]\n",
    "    max_len = max(len(x) for x in ids)\n",
    "    dense_shape=(len(ids), max_len)\n",
    "    values=[item for sublist in ids for item in sublist]\n",
    "    indices=[[row,col] for row in range(len(ids)) for col in range(len(ids[row]))]\n",
    "    return (values, indices, dense_shape)\n",
    "\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    module = hub.Module(module_url)\n",
    "    input_placeholder = tf.compat.v1.sparse_placeholder(tf.int64, shape=[None, None])\n",
    "    encodings = module(inputs=dict(values=input_placeholder.values,\n",
    "                                   indices=input_placeholder.indices,\n",
    "                                   dense_shape=input_placeholder.dense_shape\n",
    "                                  )\n",
    "                      )\n",
    "    \n",
    "    # Load the SentencePiece model.\n",
    "    # This model is conveniently stored inside the module's assets.\n",
    "    # It has to be loaded in order to initialize the processor.\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        spm_path = sess.run(module(signature=\"spm_path\"))\n",
    "        sp = spm.SentencePieceProcessor()\n",
    "        sp.Load(spm_path)\n",
    "        print(\"SentencePiece model loaded at {}.\".format(spm_path))\n",
    "\n",
    "    init_op = tf.group([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "\n",
    "GRAPH_PB_PATH = ('/opt/ml/bert_lite_module_cache/' + \n",
    "             hashlib.sha1(module_url.encode(\"utf8\")).hexdigest())\n",
    "\n",
    "print('********** Encoder saved at: **********')\n",
    "print(GRAPH_PB_PATH)\n",
    "print('********** Listing BERT-Lite artifacts on host **********')\n",
    "encoder_files = glob.glob(GRAPH_PB_PATH+\"/*\")\n",
    "print(encoder_files)\n",
    "    \n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"A modified model_fn method that returns a TF session of a tf_hub sentence \n",
    "       encoder module along with the sagemaker trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        module = hub.Module(GRAPH_PB_PATH)\n",
    "        input_placeholder = tf.compat.v1.sparse_placeholder(tf.int64, shape=[None, None])\n",
    "        encodings = module(inputs=dict(values=input_placeholder.values,\n",
    "                                       indices=input_placeholder.indices,\n",
    "                                       dense_shape=input_placeholder.dense_shape\n",
    "                                      )\n",
    "                          )\n",
    "\n",
    "        # Load the SentencePiece model.\n",
    "        # This model is conveniently stored inside the module's assets.\n",
    "        # It has to be loaded in order to initialize the processor.\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            spm_path = sess.run(module(signature=\"spm_path\"))\n",
    "            sp = spm.SentencePieceProcessor()\n",
    "            sp.Load(spm_path)\n",
    "            print(\"SentencePiece model loaded at {}.\".format(spm_path))\n",
    "\n",
    "        init_op = tf.group([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])\n",
    "    g.finalize()\n",
    "\n",
    "    # Create session and initialize.\n",
    "    session = tf.compat.v1.Session(graph=g)\n",
    "    session.run(init_op)\n",
    "    \n",
    "    return input_placeholder, encodings, sp, session\n",
    "\n",
    "\n",
    "def input_fn(input_data, content_type):\n",
    "    \"\"\"This function deserializes the input data into an object\n",
    "       that is passed into the prediction_fn function.\n",
    "       It currently only takes csv input.\n",
    "    \"\"\"\n",
    "    if content_type == 'text/csv':\n",
    "        # Read the raw input data as CSV.\n",
    "        deserialized_input_data = pd.read_csv(StringIO(input_data), \n",
    "                                              header=None\n",
    "                                             )\n",
    "        deserialized_input_data.columns = ['summary']\n",
    "\n",
    "        return deserialized_input_data\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"This function takes the output of the input_fn function\n",
    "       and passes it into the loaded model.\n",
    "    \"\"\"\n",
    "    # Parse artifacts\n",
    "    input_placeholder, encodings, sp, session = model\n",
    "\n",
    "    # Encode concept using tfhub sentence encoder\n",
    "    values, indices, dense_shape = process_to_IDs_in_sparse_format(sp, list(input_data.summary))\n",
    "    \n",
    "    encoded_concept =  session.run(encodings,\n",
    "                                   feed_dict={input_placeholder.values: values,\n",
    "                                              input_placeholder.indices: indices,\n",
    "                                              input_placeholder.dense_shape: dense_shape\n",
    "                                             }\n",
    "                                  )\n",
    "    encoded_concept_reshaped = encoded_concept.reshape(1, -1)\n",
    "\n",
    "\n",
    "    \n",
    "    return encoded_concept_reshaped\n",
    "\n",
    "\n",
    "def _npy_dumps(data):\n",
    "    \"\"\"Serializes a numpy array into a stream of npy-formatted bytes.\"\"\"\n",
    "    buffer = BytesIO()\n",
    "    np.save(buffer, data)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "\n",
    "def output_fn(prediction_output, accept):\n",
    "    if accept == 'application/x-npy':\n",
    "        print('output_fn input is', prediction_output, 'in format', accept)\n",
    "        return _npy_dumps(prediction_output), 'application/x-npy'\n",
    "    elif accept == 'application/json':\n",
    "        print('output_fn input is', prediction_output, 'in format', accept)\n",
    "        return worker.Response(encoders.encode(prediction_output, accept), accept, mimetype=accept)\n",
    "    else:\n",
    "        raise ValueError('Accept header must be application/x-npy or application/json, but it is {}'.format(accept))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('*********No training needed, we will simply pull the model from tfhub at deployment***********')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the entry-point training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_estimator = SKLearn(entry_point='text_encoder.py',\n",
    "                        role=role,\n",
    "                        instance_count=1,\n",
    "                        instance_type=\"ml.c5.9xlarge\",\n",
    "                        framework_version='0.20.0',\n",
    "                        output_path = 's3://{}'.format(BUCKET)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-26 19:18:53 Starting - Starting the training job...\n",
      "2021-01-26 19:19:16 Starting - Launching requested ML instancesProfilerReport-1611688732: InProgress\n",
      ".........\n",
      "2021-01-26 19:20:37 Starting - Preparing the instances for training...\n",
      "2021-01-26 19:21:17 Downloading - Downloading input data\n",
      "2021-01-26 19:21:17 Training - Downloading the training image.....\u001b[34m2021-01-26 19:21:58,309 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-01-26 19:21:58,311 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-26 19:21:58,319 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-01-26 19:21:58,531 botocore.utils INFO     IMDS ENDPOINT: http://169.254.169.254/\u001b[0m\n",
      "\u001b[34m2021-01-26 19:21:58,710 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:04,996 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:05,006 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:05,014 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"text-encoder-2021-01-26-19-18-48\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://text-encoder-227921966468/text-encoder-2021-01-26-19-18-48/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"text_encoder\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 36,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"text_encoder.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=text_encoder.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=text_encoder\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=36\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://text-encoder-227921966468/text-encoder-2021-01-26-19-18-48/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"text-encoder-2021-01-26-19-18-48\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://text-encoder-227921966468/text-encoder-2021-01-26-19-18-48/source/sourcedir.tar.gz\",\"module_name\":\"text_encoder\",\"network_interface_name\":\"eth0\",\"num_cpus\":36,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"text_encoder.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python text_encoder.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34m********** Pip Install TF-Hub **********\u001b[0m\n",
      "\u001b[34mCollecting setuptools\n",
      "  Downloading setuptools-52.0.0-py3-none-any.whl (784 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 50.3.0.post20201006\u001b[0m\n",
      "\u001b[34m    Uninstalling setuptools-50.3.0.post20201006:\n",
      "      Successfully uninstalled setuptools-50.3.0.post20201006\u001b[0m\n",
      "\u001b[34mSuccessfully installed setuptools-52.0.0\u001b[0m\n",
      "\n",
      "2021-01-26 19:22:18 Training - Training image download completed. Training in progress.\n",
      "2021-01-26 19:22:49 Uploading - Uploading generated training model\n",
      "2021-01-26 19:22:49 Completed - Training job completed\n",
      "\u001b[34m2021-01-26 19:22:33.199216: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:33.199252: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m********** Copying BERT-Lite **********\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:36.736347: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:36.736567: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:36.736578: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:36.736601: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-105-203.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:36.736841: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:36.738850: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:37.334470: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:37.477234: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\u001b[0m\n",
      "\u001b[34mSentencePiece model loaded at b'/opt/ml/bert_lite_module_cache/539544f0a997d91c327c23285ea00c37588d92cc/assets/universal_encoder_8k_spm.model'.\u001b[0m\n",
      "\u001b[34m********** Encoder saved at: **********\u001b[0m\n",
      "\u001b[34m/opt/ml/bert_lite_module_cache/539544f0a997d91c327c23285ea00c37588d92cc\u001b[0m\n",
      "\u001b[34m********** Listing BERT-Lite artifacts on host **********\u001b[0m\n",
      "\u001b[34m['/opt/ml/bert_lite_module_cache/539544f0a997d91c327c23285ea00c37588d92cc/variables', '/opt/ml/bert_lite_module_cache/539544f0a997d91c327c23285ea00c37588d92cc/tfhub_module.pb', '/opt/ml/bert_lite_module_cache/539544f0a997d91c327c23285ea00c37588d92cc/assets', '/opt/ml/bert_lite_module_cache/539544f0a997d91c327c23285ea00c37588d92cc/saved_model.pb']\u001b[0m\n",
      "\u001b[34m*********No training needed, we will simply pull the model from tfhub at deployment***********\u001b[0m\n",
      "\u001b[34m2021-01-26 19:22:37,931 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 101\n",
      "Billable seconds: 101\n"
     ]
    }
   ],
   "source": [
    "job_name = \"{}-{}\".format(ENDPOINT_NAME, WORKFLOW_DATE_TIME)\n",
    "knn_estimator.fit(job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: here we have to manually upload a .tar.gz file to take the role of model object... we will upload an empty file since the endpoint will be using a pre-trained model from tfhub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact is expected at s3://text-encoder-227921966468/text-encoder-2021-01-26-19-18-48/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=knn_estimator.latest_training_job.name\n",
    ")['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print('Model artifact is expected at ' + artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "source = 'model.tar.gz'\n",
    "s3_path = \"{}/output/model.tar.gz\".format(job_name)\n",
    "tar = tarfile.open(source, 'w:gz')\n",
    "#tar.add (<model binaries>)\n",
    "tar.close()\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(source, BUCKET, s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----"
     ]
    }
   ],
   "source": [
    "predictor = knn_estimator.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.c5.9xlarge',\n",
    "                                 endpoint_name=ENDPOINT_NAME\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payload = pd.DataFrame([\"When CIA analyst Jack Ryan stumbles upon a suspicious series of bank transfers his search for answers pulls him from the safety of his desk job and catapults him into a deadly game of cat\"])\n",
    "\n",
    "serialized_payload = payload.to_csv(header=False, index=False).encode('utf-8')\n",
    "\n",
    "serialized_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                   Body=serialized_payload,\n",
    "                                   ContentType='text/csv'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_string = response['Body'].read()#.decode('utf-8')\n",
    "\n",
    "response_dict = json.loads(response_string)\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
